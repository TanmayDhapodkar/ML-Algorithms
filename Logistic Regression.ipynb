{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gmat  gpa  work_experience  admitted\n",
      "0    780  4.0                3         1\n",
      "1    750  3.9                4         1\n",
      "2    690  3.3                3         0\n",
      "3    710  3.7                5         1\n",
      "4    680  3.9                4         0\n",
      "5    730  3.7                6         1\n",
      "6    690  2.3                1         0\n",
      "7    720  3.3                4         1\n",
      "8    740  3.3                5         1\n",
      "9    690  1.7                1         0\n",
      "10   610  2.7                3         0\n",
      "11   690  3.7                5         1\n",
      "12   710  3.7                6         1\n",
      "13   680  3.3                4         0\n",
      "14   770  3.3                3         1\n",
      "15   610  3.0                1         0\n",
      "16   580  2.7                4         0\n",
      "17   650  3.7                6         1\n",
      "18   540  2.7                2         0\n",
      "19   590  2.3                3         0\n",
      "20   620  3.3                2         1\n",
      "21   600  2.0                1         0\n",
      "22   550  2.3                4         0\n",
      "23   550  2.7                1         0\n",
      "24   570  3.0                2         0\n",
      "25   670  3.3                6         1\n",
      "26   660  3.7                4         1\n",
      "27   580  2.3                2         0\n",
      "28   650  3.7                6         1\n",
      "29   660  3.3                5         1\n",
      "30   640  3.0                1         0\n",
      "31   620  2.7                2         0\n",
      "32   660  4.0                4         1\n",
      "33   660  3.3                6         1\n",
      "34   680  3.3                5         1\n",
      "35   650  2.3                1         0\n",
      "36   670  2.7                2         0\n",
      "37   580  3.3                1         0\n",
      "38   590  1.7                4         0\n",
      "39   690  3.7                5         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gmat', 'gpa','work_experience']]\n",
    "y = df['admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10645164\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "y_pred=logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x282383d1240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_candidates = {'gmat': [590,740,680,610,710],\n",
    "                  'gpa': [2,3.7,3.3,2.3,3],\n",
    "                  'work_experience': [3,4,6,1,5]\n",
    "                  }\n",
    "\n",
    "df2 = pd.DataFrame(new_candidates,columns= ['gmat', 'gpa','work_experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gmat  gpa  work_experience\n",
      "0   590  2.0                3\n",
      "1   740  3.7                4\n",
      "2   680  3.3                6\n",
      "3   610  2.3                1\n",
      "4   710  3.0                5\n",
      "[0 1 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10645164\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "\n",
    "\n",
    "X = df[['gmat', 'gpa','work_experience']]\n",
    "y = df['admitted']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)  #in this case, you may choose to set the test_size=0. You should get the same prediction here\n",
    "\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "new_candidates = {'gmat': [590,740,680,610,710],\n",
    "                  'gpa': [2,3.7,3.3,2.3,3],\n",
    "                  'work_experience': [3,4,6,1,5]\n",
    "                  }\n",
    "\n",
    "df2 = pd.DataFrame(new_candidates,columns= ['gmat', 'gpa','work_experience'])\n",
    "y_pred=logistic_regression.predict(df2)\n",
    "\n",
    "print (df2)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
